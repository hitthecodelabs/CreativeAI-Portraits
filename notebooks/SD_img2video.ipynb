{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LItEqAV8Qnr1",
    "outputId": "35337e8e-b04f-4b14-aa86-5a720ee65f4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 25 22:26:41 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   62C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fhAB0-waROXc"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjxCz6HqQ7rY",
    "outputId": "0214aef8-292f-424b-8de0-4b8fb9a7d402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-25 20:18:08--  https://raw.githubusercontent.com/sagiodev/stable-video-diffusion-img2vid/main/examples/test.jpg\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 276307 (270K) [image/jpeg]\n",
      "Saving to: ‘test.jpg.1’\n",
      "\n",
      "test.jpg.1          100%[===================>] 269.83K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2024-01-25 20:18:08 (7.74 MB/s) - ‘test.jpg.1’ saved [276307/276307]\n",
      "\n",
      "Test OK\n"
     ]
    }
   ],
   "source": [
    "#@title <font size=\"6\" color=\"orange\">Stable Video Diffusion img2vid</font>\n",
    "#@markdown #### [stable-diffusion-art.com](https://stable-diffusion-art.com/stable-video-diffusion-img2vid/)\n",
    "#@markdown Click the public link `gradio.live` to start\n",
    "Save_in_Google_Drive = True #@param {type:\"boolean\"}\n",
    "Google_Drive_output_path = 'AI_PICS/img2vid' #@param {type:\"string\"}\n",
    "os.makedirs(Google_Drive_output_path, exist_ok=True)\n",
    "Clear_Log = True #@param{type:'boolean'}\n",
    "\n",
    "output_path = '/content/drive/MyDrive/' + Google_Drive_output_path\n",
    "\n",
    "import PIL\n",
    "# Has to use the Image open once for some reason, other jpg upload would fail\n",
    "!wget https://raw.githubusercontent.com/sagiodev/stable-video-diffusion-img2vid/main/examples/test.jpg\n",
    "test = PIL.Image.open(\"test.jpg\")\n",
    "print(\"Test OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Omf57UO4RiL2"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"checkpoints\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VvaTamMwRbG6",
    "outputId": "d5a69740-314c-486c-99b9-2556f072ff72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'generative-models'...\n",
      "remote: Enumerating objects: 850, done.\u001b[K\n",
      "remote: Counting objects: 100% (481/481), done.\u001b[K\n",
      "remote: Compressing objects: 100% (219/219), done.\u001b[K\n",
      "remote: Total 850 (delta 361), reused 262 (delta 262), pack-reused 369\u001b[K\n",
      "Receiving objects: 100% (850/850), 42.66 MiB | 14.83 MiB/s, done.\n",
      "Resolving deltas: 100% (437/437), done.\n",
      "Updating files: 100% (110/110), done.\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m569.1/569.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m716.4/716.4 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m371.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lida 0.0.10 requires kaleido, which is not installed.\n",
      "llmx 0.0.15a0 requires cohere, which is not installed.\n",
      "llmx 0.0.15a0 requires openai, which is not installed.\n",
      "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
      "bigframes 0.19.2 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.0 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.2.0 which is incompatible.\n",
      "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\n",
      "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
      "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1+cu118 which is incompatible.\n",
      "torchtext 0.16.0 requires torchdata==0.7.0, but you have torchdata 0.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building editable for sgm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "The following additional packages will be installed:\n",
      "  libaria2-0 libc-ares2\n",
      "The following NEW packages will be installed:\n",
      "  aria2 libaria2-0 libc-ares2\n",
      "0 upgraded, 3 newly installed, 0 to remove and 30 not upgraded.\n",
      "Need to get 1,513 kB of archives.\n",
      "After this operation, 5,441 kB of additional disk space will be used.\n",
      "Selecting previously unselected package libc-ares2:amd64.\n",
      "(Reading database ... 121671 files and directories currently installed.)\n",
      "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.2_amd64.deb ...\n",
      "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
      "Selecting previously unselected package libaria2-0:amd64.\n",
      "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
      "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
      "Selecting previously unselected package aria2.\n",
      "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
      "Unpacking aria2 (1.36.0-1) ...\n",
      "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
      "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
      "Setting up aria2 (1.36.0-1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      " *** Download Progress Summary as of Thu Jan 25 20:27:33 2024 *** \n",
      "=\n",
      "[#7a975b 353MiB/8.9GiB(3%) CN:16 DL:33MiB ETA:4m18s]\n",
      "FILE: checkpoints/svd_xt.safetensors\n",
      "-\n",
      "\n",
      " *** Download Progress Summary as of Thu Jan 25 20:28:33 2024 *** \n",
      "=\n",
      "[#7a975b 2.2GiB/8.9GiB(25%) CN:16 DL:30MiB ETA:3m42s]\n",
      "FILE: checkpoints/svd_xt.safetensors\n",
      "-\n",
      "\n",
      " *** Download Progress Summary as of Thu Jan 25 20:29:34 2024 *** \n",
      "=\n",
      "[#7a975b 4.0GiB/8.9GiB(45%) CN:16 DL:31MiB ETA:2m39s]\n",
      "FILE: checkpoints/svd_xt.safetensors\n",
      "-\n",
      "\n",
      " *** Download Progress Summary as of Thu Jan 25 20:30:35 2024 *** \n",
      "=\n",
      "[#7a975b 5.7GiB/8.9GiB(64%) CN:16 DL:27MiB ETA:1m58s]\n",
      "FILE: checkpoints/svd_xt.safetensors\n",
      "-\n",
      "\n",
      " *** Download Progress Summary as of Thu Jan 25 20:31:35 2024 *** \n",
      "=\n",
      "[#7a975b 7.1GiB/8.9GiB(80%) CN:16 DL:24MiB ETA:1m13s]\n",
      "FILE: checkpoints/svd_xt.safetensors\n",
      "-\n",
      "\n",
      " *** Download Progress Summary as of Thu Jan 25 20:32:36 2024 *** \n",
      "=\n",
      "[#7a975b 8.7GiB/8.9GiB(97%) CN:16 DL:26MiB ETA:6s]\n",
      "FILE: checkpoints/svd_xt.safetensors\n",
      "-\n",
      "\n",
      "\u001b[0m\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "7a975b|\u001b[1;32mOK\u001b[0m  |    28MiB/s|checkpoints/svd_xt.safetensors\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b dev https://github.com/camenduru/generative-models\n",
    "!pip install -q -r https://github.com/camenduru/stable-video-diffusion-colab/raw/main/requirements.txt\n",
    "!pip install -q -e generative-models\n",
    "!pip install -q -e git+https://github.com/Stability-AI/datapipelines@main#egg=sdata\n",
    "\n",
    "!apt -y install -qq aria2\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/vdo/stable-video-diffusion-img2vid-xt/resolve/main/svd_xt.safetensors?download=true -d checkpoints -o svd_xt.safetensors\n",
    "\n",
    "!mkdir -p scripts/util/detection\n",
    "!ln -s generative-models/scripts/util/detection/p_head_v1.npz scripts/util/detection/p_head_v1.npz\n",
    "!ln -s generative-models/scripts/util/detection/w_head_v1.npz scripts/util/detection/w_head_v1.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KV6T5FUBX1h1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xN19Em0YM6_"
   },
   "outputs": [],
   "source": [
    "!pip install -q -r https://github.com/camenduru/stable-video-diffusion-colab/raw/main/requirements.txt\n",
    "!pip install -q -e generative-models\n",
    "!pip install -q -e git+https://github.com/Stability-AI/datapipelines@main#egg=sdata\n",
    "\n",
    "!apt -y install -qq aria2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nxupR3dqRtuF"
   },
   "outputs": [],
   "source": [
    "import os, math, torch, cv2\n",
    "from glob import glob\n",
    "from omegaconf import OmegaConf\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import functional as TF\n",
    "from sgm.util import instantiate_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eqNlp6RvU5jx"
   },
   "outputs": [],
   "source": [
    "def load_model(config: str, device: str, num_frames: int, num_steps: int):\n",
    "    config = OmegaConf.load(config)\n",
    "    config.model.params.conditioner_config.params.emb_models[0].params.open_clip_embedding_config.params.init_device = device\n",
    "    config.model.params.sampler_config.params.num_steps = num_steps\n",
    "    config.model.params.sampler_config.params.guider_config.params.num_frames = (num_frames)\n",
    "    with torch.device(device):\n",
    "        model = instantiate_from_config(config.model).to(device).eval().requires_grad_(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCgu-GGWZ-FW",
    "outputId": "0ac9b723-548f-48e9-ff0b-d5bb9a9d81f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CODEOWNERS',\n",
       " 'LICENSE-CODE',\n",
       " 'README.md',\n",
       " 'assets',\n",
       " 'configs',\n",
       " 'data',\n",
       " 'main.py',\n",
       " 'model_licenses',\n",
       " 'pyproject.toml',\n",
       " 'pytest.ini',\n",
       " 'requirements',\n",
       " 'scripts',\n",
       " 'sgm',\n",
       " 'tests',\n",
       " 'src']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "mkKRVFBKZp5p",
    "outputId": "7a78e5ca-003f-4a5b-96d2-1625b3da076d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_frames = 25\n",
    "num_steps = 30\n",
    "model_config = \"scripts/sampling/configs/svd_xt.yaml\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "W1o9wZHgaRkG",
    "outputId": "b7cdfc19-a890-4a71-df94-3412dea1c902"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'scripts/sampling/configs/svd_xt.yaml'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EVA7vDDjaS8H"
   },
   "outputs": [],
   "source": [
    "# !cat scripts/sampling/configs/svd_xt.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgNsTDyCcNFK",
    "outputId": "86546765-440b-40d1-f0f8-e13631194325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "Initialized embedder #0: FrozenOpenCLIPImagePredictionEmbedder with 683800065 params. Trainable: False\n",
      "Initialized embedder #1: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Initialized embedder #2: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Initialized embedder #3: VideoPredictionEmbedderWithEncoder with 83653863 params. Trainable: False\n",
      "Initialized embedder #4: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Restored from ../checkpoints/svd_xt.safetensors with 0 missing and 0 unexpected keys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiffusionEngine(\n",
       "  (model): OpenAIWrapper(\n",
       "    (diffusion_model): VideoUNet(\n",
       "      (time_embed): Sequential(\n",
       "        (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (label_emb): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=1280, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (input_blocks): ModuleList(\n",
       "        (0): TimestepEmbedSequential(\n",
       "          (0): Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1-2): 2 x TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (1): SpatialVideoTransformer(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (time_stack): ModuleList(\n",
       "              (0): VideoTransformerBlock(\n",
       "                (norm_in): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff_in): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (time_pos_embed): Sequential(\n",
       "              (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "        )\n",
       "        (3): TimestepEmbedSequential(\n",
       "          (0): Downsample(\n",
       "            (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (4): TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (1): SpatialVideoTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (time_stack): ModuleList(\n",
       "              (0): VideoTransformerBlock(\n",
       "                (norm_in): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff_in): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (time_pos_embed): Sequential(\n",
       "              (0): Linear(in_features=640, out_features=2560, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "        )\n",
       "        (5): TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (1): SpatialVideoTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (time_stack): ModuleList(\n",
       "              (0): VideoTransformerBlock(\n",
       "                (norm_in): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff_in): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (time_pos_embed): Sequential(\n",
       "              (0): Linear(in_features=640, out_features=2560, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "        )\n",
       "        (6): TimestepEmbedSequential(\n",
       "          (0): Downsample(\n",
       "            (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (7): TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (1): SpatialVideoTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (time_stack): ModuleList(\n",
       "              (0): VideoTransformerBlock(\n",
       "                (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff_in): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (time_pos_embed): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "        )\n",
       "        (8): TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (1): SpatialVideoTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (time_stack): ModuleList(\n",
       "              (0): VideoTransformerBlock(\n",
       "                (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff_in): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (time_pos_embed): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "        )\n",
       "        (9): TimestepEmbedSequential(\n",
       "          (0): Downsample(\n",
       "            (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (10-11): 2 x TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (middle_block): TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (2): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (output_blocks): ModuleList(\n",
       "        (0-1): 2 x TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "        )\n",
       "        (2): TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (1): Upsample(\n",
       "            (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3-4): 2 x TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (1): SpatialVideoTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (time_stack): ModuleList(\n",
       "              (0): VideoTransformerBlock(\n",
       "                (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff_in): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (time_pos_embed): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "        )\n",
       "        (5): TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (1): SpatialVideoTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (time_stack): ModuleList(\n",
       "              (0): VideoTransformerBlock(\n",
       "                (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff_in): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (time_pos_embed): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (2): Upsample(\n",
       "            (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (6): TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (1): SpatialVideoTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (time_stack): ModuleList(\n",
       "              (0): VideoTransformerBlock(\n",
       "                (norm_in): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff_in): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (time_pos_embed): Sequential(\n",
       "              (0): Linear(in_features=640, out_features=2560, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "        )\n",
       "        (7): TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (1): SpatialVideoTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (time_stack): ModuleList(\n",
       "              (0): VideoTransformerBlock(\n",
       "                (norm_in): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff_in): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (time_pos_embed): Sequential(\n",
       "              (0): Linear(in_features=640, out_features=2560, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "        )\n",
       "        (8): TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (1): SpatialVideoTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (time_stack): ModuleList(\n",
       "              (0): VideoTransformerBlock(\n",
       "                (norm_in): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff_in): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (time_pos_embed): Sequential(\n",
       "              (0): Linear(in_features=640, out_features=2560, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (2): Upsample(\n",
       "            (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (9): TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (1): SpatialVideoTransformer(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (time_stack): ModuleList(\n",
       "              (0): VideoTransformerBlock(\n",
       "                (norm_in): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff_in): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (time_pos_embed): Sequential(\n",
       "              (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "        )\n",
       "        (10-11): 2 x TimestepEmbedSequential(\n",
       "          (0): VideoResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (time_stack): ResBlock(\n",
       "              (in_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (h_upd): Identity()\n",
       "              (x_upd): Identity()\n",
       "              (emb_layers): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "              (out_layers): Sequential(\n",
       "                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "                (1): SiLU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "              )\n",
       "              (skip_connection): Identity()\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "          (1): SpatialVideoTransformer(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (time_stack): ModuleList(\n",
       "              (0): VideoTransformerBlock(\n",
       "                (norm_in): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff_in): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn1): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): MemoryEfficientCrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (time_pos_embed): Sequential(\n",
       "              (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (time_mixer): AlphaBlender()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (out): Sequential(\n",
       "        (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (denoiser): Denoiser()\n",
       "  (conditioner): GeneralConditioner(\n",
       "    (embedders): ModuleList(\n",
       "      (0): FrozenOpenCLIPImagePredictionEmbedder(\n",
       "        (open_clip): FrozenOpenCLIPImageEmbedder(\n",
       "          (model): CLIP(\n",
       "            (visual): VisionTransformer(\n",
       "              (conv1): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "              (patch_dropout): Identity()\n",
       "              (ln_pre): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (transformer): Transformer(\n",
       "                (resblocks): ModuleList(\n",
       "                  (0-31): 32 x ResidualAttentionBlock(\n",
       "                    (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attn): MultiheadAttention(\n",
       "                      (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                    )\n",
       "                    (ls_1): Identity()\n",
       "                    (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                    (mlp): Sequential(\n",
       "                      (c_fc): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                      (gelu): GELU(approximate='none')\n",
       "                      (c_proj): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                    )\n",
       "                    (ls_2): Identity()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (ln_post): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (token_embedding): Embedding(49408, 1024)\n",
       "            (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-2): 2 x ConcatTimestepEmbedderND(\n",
       "        (timestep): Timestep()\n",
       "      )\n",
       "      (3): VideoPredictionEmbedderWithEncoder(\n",
       "        (encoder): AutoencoderKLModeOnly(\n",
       "          (encoder): Encoder(\n",
       "            (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (down): ModuleList(\n",
       "              (0): Module(\n",
       "                (block): ModuleList(\n",
       "                  (0-1): 2 x ResnetBlock(\n",
       "                    (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "                    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "                (attn): ModuleList()\n",
       "                (downsample): Downsample(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "                )\n",
       "              )\n",
       "              (1): Module(\n",
       "                (block): ModuleList(\n",
       "                  (0): ResnetBlock(\n",
       "                    (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "                    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  )\n",
       "                  (1): ResnetBlock(\n",
       "                    (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "                    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "                (attn): ModuleList()\n",
       "                (downsample): Downsample(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "                )\n",
       "              )\n",
       "              (2): Module(\n",
       "                (block): ModuleList(\n",
       "                  (0): ResnetBlock(\n",
       "                    (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "                    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  )\n",
       "                  (1): ResnetBlock(\n",
       "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "                (attn): ModuleList()\n",
       "                (downsample): Downsample(\n",
       "                  (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "                )\n",
       "              )\n",
       "              (3): Module(\n",
       "                (block): ModuleList(\n",
       "                  (0-1): 2 x ResnetBlock(\n",
       "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "                (attn): ModuleList()\n",
       "              )\n",
       "            )\n",
       "            (mid): Module(\n",
       "              (block_1): ResnetBlock(\n",
       "                (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (attn_1): MemoryEfficientAttnBlock(\n",
       "                (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (block_2): ResnetBlock(\n",
       "                (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (decoder): Decoder(\n",
       "            (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (mid): Module(\n",
       "              (block_1): ResnetBlock(\n",
       "                (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (attn_1): MemoryEfficientAttnBlock(\n",
       "                (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (block_2): ResnetBlock(\n",
       "                (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (up): ModuleList(\n",
       "              (0): Module(\n",
       "                (block): ModuleList(\n",
       "                  (0): ResnetBlock(\n",
       "                    (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "                    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  )\n",
       "                  (1-2): 2 x ResnetBlock(\n",
       "                    (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "                    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "                (attn): ModuleList()\n",
       "              )\n",
       "              (1): Module(\n",
       "                (block): ModuleList(\n",
       "                  (0): ResnetBlock(\n",
       "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  )\n",
       "                  (1-2): 2 x ResnetBlock(\n",
       "                    (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "                    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "                (attn): ModuleList()\n",
       "                (upsample): Upsample(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                )\n",
       "              )\n",
       "              (2-3): 2 x Module(\n",
       "                (block): ModuleList(\n",
       "                  (0-2): 3 x ResnetBlock(\n",
       "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "                (attn): ModuleList()\n",
       "                (upsample): Upsample(\n",
       "                  (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (loss): Identity()\n",
       "          (regularization): DiagonalGaussianRegularizer()\n",
       "          (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConcatTimestepEmbedderND(\n",
       "        (timestep): Timestep()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (first_stage_model): AutoencodingEngine(\n",
       "    (encoder): Encoder(\n",
       "      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (down): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (2): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (3): Module(\n",
       "          (block): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "        )\n",
       "      )\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (attn_1): AttnBlock(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (decoder): VideoDecoder(\n",
       "      (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (mid): Module(\n",
       "        (block_1): NewCls(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "        )\n",
       "        (attn_1): AttnBlock(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (block_2): NewCls(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (up): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): NewCls(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (time_stack): ResBlock(\n",
       "                (in_layers): Sequential(\n",
       "                  (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "                )\n",
       "                (h_upd): Identity()\n",
       "                (x_upd): Identity()\n",
       "                (out_layers): Sequential(\n",
       "                  (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "                  (1): SiLU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                  (3): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "                )\n",
       "                (skip_connection): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1-2): 2 x NewCls(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (time_stack): ResBlock(\n",
       "                (in_layers): Sequential(\n",
       "                  (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "                )\n",
       "                (h_upd): Identity()\n",
       "                (x_upd): Identity()\n",
       "                (out_layers): Sequential(\n",
       "                  (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "                  (1): SiLU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                  (3): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "                )\n",
       "                (skip_connection): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): NewCls(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (time_stack): ResBlock(\n",
       "                (in_layers): Sequential(\n",
       "                  (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "                )\n",
       "                (h_upd): Identity()\n",
       "                (x_upd): Identity()\n",
       "                (out_layers): Sequential(\n",
       "                  (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "                  (1): SiLU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                  (3): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "                )\n",
       "                (skip_connection): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1-2): 2 x NewCls(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (time_stack): ResBlock(\n",
       "                (in_layers): Sequential(\n",
       "                  (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "                )\n",
       "                (h_upd): Identity()\n",
       "                (x_upd): Identity()\n",
       "                (out_layers): Sequential(\n",
       "                  (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "                  (1): SiLU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                  (3): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "                )\n",
       "                (skip_connection): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2-3): 2 x Module(\n",
       "          (block): ModuleList(\n",
       "            (0-2): 3 x NewCls(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (time_stack): ResBlock(\n",
       "                (in_layers): Sequential(\n",
       "                  (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "                )\n",
       "                (h_upd): Identity()\n",
       "                (x_upd): Identity()\n",
       "                (out_layers): Sequential(\n",
       "                  (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "                  (1): SiLU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                  (3): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "                )\n",
       "                (skip_connection): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "      (conv_out): NewCls(\n",
       "        128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (time_mix_conv): Conv3d(3, 3, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "      )\n",
       "    )\n",
       "    (loss): Identity()\n",
       "    (regularization): DiagonalGaussianRegularizer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(model_config, device, num_frames, num_steps)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "E_A-Brr6U4_U"
   },
   "outputs": [],
   "source": [
    "model.conditioner.cpu()\n",
    "model.first_stage_model.cpu()\n",
    "model.model.to(dtype=torch.float16)\n",
    "torch.cuda.empty_cache()\n",
    "model = model.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NBc_StCLVe3y"
   },
   "outputs": [],
   "source": [
    "def get_unique_embedder_keys_from_conditioner(conditioner):\n",
    "    return list(set([x.input_key for x in conditioner.embedders]))\n",
    "\n",
    "def get_batch(keys, value_dict, N, T, device, dtype=None):\n",
    "    batch = {}\n",
    "    batch_uc = {}\n",
    "    for key in keys:\n",
    "        if key == \"fps_id\":\n",
    "            batch[key] = (\n",
    "                torch.tensor([value_dict[\"fps_id\"]])\n",
    "                .to(device, dtype=dtype)\n",
    "                .repeat(int(math.prod(N)))\n",
    "            )\n",
    "        elif key == \"motion_bucket_id\":\n",
    "            batch[key] = (\n",
    "                torch.tensor([value_dict[\"motion_bucket_id\"]])\n",
    "                .to(device, dtype=dtype)\n",
    "                .repeat(int(math.prod(N)))\n",
    "            )\n",
    "        elif key == \"cond_aug\":\n",
    "            batch[key] = repeat(\n",
    "                torch.tensor([value_dict[\"cond_aug\"]]).to(device, dtype=dtype),\n",
    "                \"1 -> b\",\n",
    "                b=math.prod(N),\n",
    "            )\n",
    "        elif key == \"cond_frames\":\n",
    "            batch[key] = repeat(value_dict[\"cond_frames\"], \"1 ... -> b ...\", b=N[0])\n",
    "        elif key == \"cond_frames_without_noise\":\n",
    "            batch[key] = repeat(\n",
    "                value_dict[\"cond_frames_without_noise\"], \"1 ... -> b ...\", b=N[0]\n",
    "            )\n",
    "        else:\n",
    "            batch[key] = value_dict[key]\n",
    "    if T is not None:\n",
    "        batch[\"num_video_frames\"] = T\n",
    "    for key in batch.keys():\n",
    "        if key not in batch_uc and isinstance(batch[key], torch.Tensor):\n",
    "            batch_uc[key] = torch.clone(batch[key])\n",
    "    return batch, batch_uc\n",
    "\n",
    "def sample(\n",
    "    input_path: str = \"/content/test_image.png\",\n",
    "    resize_image: bool = False,\n",
    "    num_frames: Optional[int] = None,\n",
    "    num_steps: Optional[int] = None,\n",
    "    fps_id: int = 6,\n",
    "    motion_bucket_id: int = 127,\n",
    "    cond_aug: float = 0.02,\n",
    "    seed: int = 23,\n",
    "    decoding_t: int = 14,  # Number of frames decoded at a time! This eats most VRAM. Reduce if necessary.\n",
    "    device: str = \"cuda\",\n",
    "    output_folder: Optional[str] = \"/content/outputs\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Simple script to generate a single sample conditioned on an image `input_path` or multiple images, one for each\n",
    "    image file in folder `input_path`. If you run out of VRAM, try decreasing `decoding_t`.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    path = Path(input_path)\n",
    "    all_img_paths = []\n",
    "    if path.is_file():\n",
    "        if any([input_path.endswith(x) for x in [\"jpg\", \"jpeg\", \"png\"]]):\n",
    "            all_img_paths = [input_path]\n",
    "        else:\n",
    "            raise ValueError(\"Path is not valid image file.\")\n",
    "    elif path.is_dir():\n",
    "        all_img_paths = sorted(\n",
    "            [\n",
    "                f\n",
    "                for f in path.iterdir()\n",
    "                if f.is_file() and f.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]\n",
    "            ]\n",
    "        )\n",
    "        if len(all_img_paths) == 0:\n",
    "            raise ValueError(\"Folder does not contain any images.\")\n",
    "    else:\n",
    "        raise ValueError\n",
    "    all_out_paths = []\n",
    "    for input_img_path in all_img_paths:\n",
    "        with Image.open(input_img_path) as image:\n",
    "            if image.mode == \"RGBA\":\n",
    "                image = image.convert(\"RGB\")\n",
    "            if resize_image and image.size != (1024, 576):\n",
    "                print(f\"Resizing {image.size} to (1024, 576)\")\n",
    "                image = TF.resize(TF.resize(image, 1024), (576, 1024))\n",
    "            w, h = image.size\n",
    "            if h % 64 != 0 or w % 64 != 0:\n",
    "                width, height = map(lambda x: x - x % 64, (w, h))\n",
    "                image = image.resize((width, height))\n",
    "                print(\n",
    "                    f\"WARNING: Your image is of size {h}x{w} which is not divisible by 64. We are resizing to {height}x{width}!\"\n",
    "                )\n",
    "            image = ToTensor()(image)\n",
    "            image = image * 2.0 - 1.0\n",
    "\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        H, W = image.shape[2:]\n",
    "        assert image.shape[1] == 3\n",
    "        F = 8\n",
    "        C = 4\n",
    "        shape = (num_frames, C, H // F, W // F)\n",
    "        if (H, W) != (576, 1024):\n",
    "            print(\n",
    "                \"WARNING: The conditioning frame you provided is not 576x1024. This leads to suboptimal performance as model was only trained on 576x1024. Consider increasing `cond_aug`.\"\n",
    "            )\n",
    "        if motion_bucket_id > 255:\n",
    "            print(\n",
    "                \"WARNING: High motion bucket! This may lead to suboptimal performance.\"\n",
    "            )\n",
    "        if fps_id < 5:\n",
    "            print(\"WARNING: Small fps value! This may lead to suboptimal performance.\")\n",
    "        if fps_id > 30:\n",
    "            print(\"WARNING: Large fps value! This may lead to suboptimal performance.\")\n",
    "\n",
    "        value_dict = {}\n",
    "        value_dict[\"motion_bucket_id\"] = motion_bucket_id\n",
    "        value_dict[\"fps_id\"] = fps_id\n",
    "        value_dict[\"cond_aug\"] = cond_aug\n",
    "        value_dict[\"cond_frames_without_noise\"] = image\n",
    "        value_dict[\"cond_frames\"] = image + cond_aug * torch.randn_like(image)\n",
    "        value_dict[\"cond_aug\"] = cond_aug\n",
    "        # low vram mode\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        model.conditioner.cpu()\n",
    "        model.first_stage_model.cpu()\n",
    "        torch.cuda.empty_cache()\n",
    "        model.sampler.verbose = True\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(device):\n",
    "                model.conditioner.to(device)\n",
    "                batch, batch_uc = get_batch(\n",
    "                    get_unique_embedder_keys_from_conditioner(model.conditioner),\n",
    "                    value_dict,\n",
    "                    [1, num_frames],\n",
    "                    T=num_frames,\n",
    "                    device=device,\n",
    "                )\n",
    "                c, uc = model.conditioner.get_unconditional_conditioning(\n",
    "                    batch,\n",
    "                    batch_uc=batch_uc,\n",
    "                    force_uc_zero_embeddings=[\n",
    "                        \"cond_frames\",\n",
    "                        \"cond_frames_without_noise\",\n",
    "                    ],\n",
    "                )\n",
    "                model.conditioner.cpu()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                # from here, dtype is fp16\n",
    "                for k in [\"crossattn\", \"concat\"]:\n",
    "                    uc[k] = repeat(uc[k], \"b ... -> b t ...\", t=num_frames)\n",
    "                    uc[k] = rearrange(uc[k], \"b t ... -> (b t) ...\", t=num_frames)\n",
    "                    c[k] = repeat(c[k], \"b ... -> b t ...\", t=num_frames)\n",
    "                    c[k] = rearrange(c[k], \"b t ... -> (b t) ...\", t=num_frames)\n",
    "                for k in uc.keys():\n",
    "                    uc[k] = uc[k].to(dtype=torch.float16)\n",
    "                    c[k] = c[k].to(dtype=torch.float16)\n",
    "\n",
    "                randn = torch.randn(shape, device=device, dtype=torch.float16)\n",
    "                additional_model_inputs = {}\n",
    "                additional_model_inputs[\"image_only_indicator\"] = torch.zeros(2, num_frames).to(device)\n",
    "                additional_model_inputs[\"num_video_frames\"] = batch[\"num_video_frames\"]\n",
    "\n",
    "                for k in additional_model_inputs:\n",
    "                    if isinstance(additional_model_inputs[k], torch.Tensor):\n",
    "                        additional_model_inputs[k] = additional_model_inputs[k].to(dtype=torch.float16)\n",
    "\n",
    "                def denoiser(input, sigma, c):\n",
    "                    return model.denoiser(model.model, input, sigma, c, **additional_model_inputs)\n",
    "\n",
    "                samples_z = model.sampler(denoiser, randn, cond=c, uc=uc)\n",
    "                samples_z.to(dtype=model.first_stage_model.dtype)\n",
    "                model.en_and_decode_n_samples_a_time = decoding_t\n",
    "                model.first_stage_model.to(device)\n",
    "                samples_x = model.decode_first_stage(samples_z)\n",
    "                samples = torch.clamp((samples_x + 1.0) / 2.0, min=0.0, max=1.0)\n",
    "                model.first_stage_model.cpu()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                os.makedirs(output_folder, exist_ok=True)\n",
    "                base_count = len(glob(os.path.join(output_folder, \"*.mp4\")))\n",
    "                video_path = os.path.join(output_folder, f\"{base_count:06d}.mp4\")\n",
    "                writer = cv2.VideoWriter(\n",
    "                    video_path,\n",
    "                    cv2.VideoWriter_fourcc(*\"MP4V\"),\n",
    "                    fps_id + 1,\n",
    "                    (samples.shape[-1], samples.shape[-2]),\n",
    "                )\n",
    "                vid = (\n",
    "                    (rearrange(samples, \"t c h w -> t h w c\") * 255)\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                    .astype(np.uint8)\n",
    "                )\n",
    "                for frame in vid:\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "                    writer.write(frame)\n",
    "                writer.release()\n",
    "                all_out_paths.append(video_path)\n",
    "    return all_out_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wocwTSsZXbKr"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import random\n",
    "\n",
    "def infer(input_path: str, resize_image: bool, n_frames: int, n_steps: int, seed: str, decoding_t: int, motion_bucket_id: int, fps_id: int) -> str:\n",
    "    if seed == \"random\":\n",
    "        seed = random.randint(0, 2**32)\n",
    "    seed = int(seed)\n",
    "    print('Seed of this video is: %d'%seed)\n",
    "    output_paths = sample(\n",
    "        input_path=input_path,\n",
    "        resize_image=resize_image,\n",
    "        num_frames=n_frames,\n",
    "        num_steps=n_steps,\n",
    "        fps_id=fps_id,\n",
    "        motion_bucket_id=127,\n",
    "        cond_aug=0.02,\n",
    "        seed=seed,\n",
    "        decoding_t=decoding_t,  # Number of frames decoded at a time! This eats most VRAM. Reduce if necessary.\n",
    "        device=device,\n",
    "        output_folder=output_path\n",
    "        )\n",
    "    return output_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9UcFC8hfKxW"
   },
   "outputs": [],
   "source": [
    "## GUI\n",
    "# clear log\n",
    "# Clear_Log = True #@param{type:'boolean'}\n",
    "Clear_Log = True\n",
    "if Clear_Log:\n",
    "    from IPython.display import clear_output\n",
    "    clear_output()\n",
    "\n",
    "output_path = 'AI_PICS/img2vid'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "resize_choices = [\"Just resize\", \"Crop and resize\"]\n",
    "resize_default_index = 1\n",
    "\n",
    "\n",
    "def clear_image(uploaded_image):\n",
    "  return None\n",
    "\n",
    "def resize_image(uploaded_image, resize_option, crop_offset, resized_image_file):\n",
    "  '''\n",
    "  Resize the input input based on the resize option.\n",
    "  Adjust the crop position based on the crop offset\n",
    "  '''\n",
    "\n",
    "  if uploaded_image is None:\n",
    "    return None\n",
    "\n",
    "  w, h = (1024, 576) # target width and height\n",
    "  old_h, old_w = uploaded_image.shape[0:2]\n",
    "\n",
    "\n",
    "  # Crop image\n",
    "  if resize_option == \"Just resize\":\n",
    "    cropped_image = uploaded_image\n",
    "  elif resize_option == \"Crop and resize\":\n",
    "    # crop to same aspect ratio\n",
    "    if w/h > old_w/old_h:\n",
    "      target_h = int(old_w * h/w)\n",
    "      padding1 = int((old_h - target_h)/2)\n",
    "      padding2 = old_h -padding1\n",
    "      padding = int(np.interp(crop_offset, [0, 0.5, 1], [0, padding1, padding1 + padding2]))\n",
    "      cropped_image = uploaded_image[padding:padding+target_h, :, :]\n",
    "    else:\n",
    "      target_w = int(old_h * w/h)\n",
    "      padding1 = int((old_w - target_w)/2)\n",
    "      padding2 = old_w - padding1\n",
    "      padding = int(np.interp(crop_offset, [0, 0.5, 1], [0, padding1, padding1 + padding2]))\n",
    "      cropped_image = uploaded_image[:, padding:padding+target_w, :]\n",
    "  else:\n",
    "    ValueError(f\"Unknown resize option: {resize_option}\")\n",
    "\n",
    "\n",
    "  # Resize image\n",
    "  resized_image_file = \"resized_image.png\"  # cannot be jpg for some reason\n",
    "  resized_image = cv2.resize(cropped_image, (w, h))\n",
    "  im = Image.fromarray(resized_image)\n",
    "  im.save(resized_image_file)\n",
    "  return resized_image,resized_image_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWR-reIZZ2-o",
    "outputId": "d6db0a93-915d-4e7b-a5f6-afbadef59bbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
      "Running on public URL: https://adbe57665270801a4b.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "Seed of this video is: 3694625572\n",
      "##############################  Sampling setting  ##############################\n",
      "Sampler: EulerEDMSampler\n",
      "Discretization: EDMDiscretization\n",
      "Guider: LinearPredictionGuider\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling with EulerEDMSampler for 31 steps:   0%|          | 0/31 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "Sampling with EulerEDMSampler for 31 steps:  97%|█████████▋| 30/31 [08:03<00:16, 16.11s/it]\n",
      "/usr/local/lib/python3.10/dist-packages/gradio/components/video.py:274: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed of this video is: 3648437925\n",
      "##############################  Sampling setting  ##############################\n",
      "Sampler: EulerEDMSampler\n",
      "Discretization: EDMDiscretization\n",
      "Guider: LinearPredictionGuider\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling with EulerEDMSampler for 31 steps:   0%|          | 0/31 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "Sampling with EulerEDMSampler for 31 steps:   0%|          | 0/31 [00:01<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"<ipython-input-11-bd3ae5c12776>\", line 9, in infer\n",
      "    output_paths = sample(\n",
      "  File \"<ipython-input-10-6948dc414a6a>\", line 174, in sample\n",
      "    samples_z = model.sampler(denoiser, randn, cond=c, uc=uc)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/sampling.py\", line 120, in __call__\n",
      "    x = self.sampler_step(\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/sampling.py\", line 99, in sampler_step\n",
      "    denoised = self.denoise(x, denoiser, sigma_hat, cond, uc)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/sampling.py\", line 55, in denoise\n",
      "    denoised = denoiser(*self.guider.prepare_inputs(x, sigma, cond, uc))\n",
      "  File \"<ipython-input-10-6948dc414a6a>\", line 172, in denoiser\n",
      "    return model.denoiser(model.model, input, sigma, c, **additional_model_inputs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/denoiser.py\", line 37, in forward\n",
      "    network(input * c_in, c_noise, cond, **additional_model_inputs) * c_out\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/wrappers.py\", line 28, in forward\n",
      "    return self.diffusion_model(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/video_model.py\", line 465, in forward\n",
      "    h = module(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/openaimodel.py\", line 93, in forward\n",
      "    x = layer(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/video_attention.py\", line 281, in forward\n",
      "    x = block(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/attention.py\", line 546, in forward\n",
      "    return checkpoint(self._forward, x, context)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py\", line 249, in checkpoint\n",
      "    return CheckpointFunction.apply(function, preserve, *args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\", line 506, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py\", line 107, in forward\n",
      "    outputs = run_function(*args)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/attention.py\", line 571, in _forward\n",
      "    x = self.ff(self.norm3(x)) + x\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/attention.py\", line 113, in forward\n",
      "    return self.net(x)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/attention.py\", line 94, in forward\n",
      "    return x * F.gelu(gate)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.11 GiB (GPU 0; 14.75 GiB total capacity; 12.50 GiB already allocated; 581.06 MiB free; 14.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"<ipython-input-11-bd3ae5c12776>\", line 9, in infer\n",
      "    output_paths = sample(\n",
      "  File \"<ipython-input-10-6948dc414a6a>\", line 174, in sample\n",
      "    samples_z = model.sampler(denoiser, randn, cond=c, uc=uc)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/sampling.py\", line 120, in __call__\n",
      "    x = self.sampler_step(\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/sampling.py\", line 99, in sampler_step\n",
      "    denoised = self.denoise(x, denoiser, sigma_hat, cond, uc)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/sampling.py\", line 55, in denoise\n",
      "    denoised = denoiser(*self.guider.prepare_inputs(x, sigma, cond, uc))\n",
      "  File \"<ipython-input-10-6948dc414a6a>\", line 172, in denoiser\n",
      "    return model.denoiser(model.model, input, sigma, c, **additional_model_inputs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/denoiser.py\", line 37, in forward\n",
      "    network(input * c_in, c_noise, cond, **additional_model_inputs) * c_out\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/wrappers.py\", line 28, in forward\n",
      "    return self.diffusion_model(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/video_model.py\", line 465, in forward\n",
      "    h = module(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/diffusionmodules/openaimodel.py\", line 93, in forward\n",
      "    x = layer(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/video_attention.py\", line 281, in forward\n",
      "    x = block(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/attention.py\", line 546, in forward\n",
      "    return checkpoint(self._forward, x, context)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py\", line 249, in checkpoint\n",
      "    return CheckpointFunction.apply(function, preserve, *args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\", line 506, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py\", line 107, in forward\n",
      "    outputs = run_function(*args)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/attention.py\", line 571, in _forward\n",
      "    x = self.ff(self.norm3(x)) + x\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/attention.py\", line 113, in forward\n",
      "    return self.net(x)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/htcl/apworc/gen_imgs/img2video/generative-models/sgm/modules/attention.py\", line 94, in forward\n",
      "    return x * F.gelu(gate)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.11 GiB (GPU 0; 14.75 GiB total capacity; 12.50 GiB already allocated; 581.06 MiB free; 14.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 501, in process_events\n",
      "    response = await self.call_prediction(awake_events, batch)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 465, in call_prediction\n",
      "    raise Exception(str(error) if show_error else None) from error\n",
      "Exception: CUDA out of memory. Tried to allocate 2.11 GiB (GPU 0; 14.75 GiB total capacity; 12.50 GiB already allocated; 581.06 MiB free; 14.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "  resized_image_file = gr.File(visible=False)\n",
    "  with gr.Column():\n",
    "    gr.Markdown(\"# Stable Diffusion Image to Video\")\n",
    "\n",
    "    with gr.Row():\n",
    "      with gr.Column():\n",
    "        gr.Markdown(\"## Upload input image\")\n",
    "        with gr.Row():\n",
    "          resize_option = gr.Radio(resize_choices, label=\"Resize mode\", value = resize_choices[resize_default_index])\n",
    "          crop_offset = gr.Slider(0, 1, value=0.5, label=\"Crop offset\")\n",
    "        input_image = gr.Image(label=\"Input image\")\n",
    "      with gr.Column():\n",
    "        gr.Markdown(\"## Resized image to be used as input\")\n",
    "        resized_image = gr.Image(label=\"Resized image\")\n",
    "\n",
    "      # trigger on uploading an input image\n",
    "      input_image.upload(resize_image, inputs =[input_image, resize_option, crop_offset, resized_image_file], outputs = [resized_image, resized_image_file])\n",
    "      # trigger on clearin the input image\n",
    "      input_image.clear(clear_image, inputs =[input_image], outputs = resized_image)\n",
    "      # triggr on changing the resize option\n",
    "      resize_option.change(resize_image, inputs =[input_image, resize_option, crop_offset, resized_image_file], outputs = [resized_image, resized_image_file])\n",
    "      # triggr on changing crop offset\n",
    "      crop_offset.change(resize_image, inputs =[input_image, resize_option, crop_offset, resized_image_file], outputs = [resized_image,resized_image_file])\n",
    "\n",
    "    btn = gr.Button(\"Run\")\n",
    "    with gr.Accordion(label=\"Advanced options\", open=False):\n",
    "      motion_bucket_id = gr.Slider(label=\"motion bucket id\", value=127, minimum = 0, maximum = 255, step = 1, info=\"Higher for more motion.\")\n",
    "      fps_id = gr.Slider(label=\"fps id\", value=6, minimum = 5, maximum = 30, step = 1, info=\"frames per second. Increase for faster frame rate.\")\n",
    "      seed = gr.Text(value=\"random\", label=\"seed (integer or 'random')\", info=\"Fixed integer for generating the same video.\")\n",
    "      n_frames = gr.Number(precision=0, label=\"number of frames\", value=num_frames)\n",
    "      n_steps = gr.Number(precision=0, label=\"number of steps\", value=num_steps)\n",
    "      decoding_t = gr.Number(precision=0, label=\"number of frames decoded at a time\", value=2, info=\"Lower to use less VRAM.\")\n",
    "\n",
    "  with gr.Column():\n",
    "    video_out = gr.Video(label=\"generated video\")\n",
    "  examples = [[\"https://user-images.githubusercontent.com/33302880/284758167-367a25d8-8d7b-42d3-8391-6d82813c7b0f.png\"]]\n",
    "  inputs = [resized_image_file, gr.Checkbox(value=True, visible=False), n_frames, n_steps, seed, decoding_t, motion_bucket_id, fps_id]\n",
    "  outputs = [video_out]\n",
    "  btn.click(infer, inputs=inputs, outputs=outputs)\n",
    "  #gr.Examples(examples=examples, inputs=inputs, outputs=outputs, fn=infer)\n",
    "  demo.queue().launch(debug=True, share=True, inline=False, show_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7jxdXxlcsox"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
